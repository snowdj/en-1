---
layout: post
title: "使用聚类分析为主题模型划分主题类型"
date: 2013-09-08 14:54
comments: true
categories: R;topic models
---



使用主题模型（topic models）可以较为高效地划分文本的主题，但一个不得不面对的问题是有时候主题的划分过细，使得解读和归类成为困难。其实，聚类分析作为一个“古老”的分析方法可以较为简洁的解决这个问题。

举一个小例子，我们主要使用tm这个R包来完成文本挖掘的前期任务。在得到DocumentTermMatrix之后，可以通过计算cosine 相似度的方法来计算文本之间的不一致性（dissimilarity）。

	# Using cluster analysis to classify topics generated by topic modeling
	# 2013 Sep 08
	# Cheng-Jun Wang

	library(tm)
	library(topicmodels)
	require(proxy)
	
	
	data(acq)
	data(crude)
	
	m <- c(acq, crude)
	dtm <- DocumentTermMatrix(m)
	dtm <- removeSparseTerms(dtm, 0.8)
	inspect(dtm[1:5, 1:5])
	
	# cluster analysis of documents based on DocumentTermMatrix
	dist_dtm <- dissimilarity(mtd, method = 'cosine')
	hc <- hclust(dist_dtm, method = 'ave')
	plot(hc, xlab = '')
{:lang="ruby"}

我在做RA的时候，面临的一个问题就是在做主体模型的时候出现的：模型拟合得到的主题数量太多。我们用下面这个例子进行简单的介绍。

	# topic modeling
	topic_num = 50
	for (k in c(topic_num))  {
	  # k <- 10
	  SEED <- 2010
	  jss_TM <- list(
	    VEM = LDA(dtm, k = k, control = list(seed = SEED)),
	    VEM_fixed = LDA(dtm, k = k, control = list(estimate.alpha = FALSE, seed = SEED)),
	    Gibbs = LDA(dtm, k = k, method = "Gibbs", 
	                control = list(seed = SEED, burnin = 1000, thin = 100, iter = 1000))    )
	}
	
	rs = posterior(jss_TM$Gibbs, dtm)
	
	mtd = t(rs$topics) # topics and documents
	mtt = rs$terms  # topic and terms
{:lang="ruby"}


使用k mean聚类方法的好处是可以较为方便地知道聚类的数量

	#########################################
	#
	# K means analysis for rownames of a matrix
	#
	#########################################
	
	
	# Determine number of clusters
	mydata = mtt
	wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
	max_group = nrow(mydata)-1
	for (i in 2:max_group) wss[i] <- sum(kmeans(mydata, 
	                                            centers=i)$withinss)
	plot(1:max_group, wss, type="b", xlab="Number of Clusters",
	     ylab="Within groups sum of squares")
	##
	# K-Means Cluster Analysis
	fit <- kmeans(mydata, 5) # 5 cluster solution
	# get cluster means 
	cluster_means = aggregate(mydata,by=list(fit$cluster),FUN=mean)
	# append cluster assignment
	mydata <- data.frame(rownames(mydata), fit$cluster)
{:lang="ruby"}

以下，我们对矩阵计算cosine similarity并使用阶层聚类方法得到结果。

	############################################
	#
	#  Hierarchical Clustering
	#
	############################################
	
	cos.sim <- function(ix) 
	{
	  A = X[ix[1],]
	  B = X[ix[2],]
	  return( sum(A*B)/sqrt(sum(A^2)*sum(B^2)) )
	}   
	
	mdt = as.matrix(dtm)
	X = mtt  # whether to scale it
	
	
	n <- nrow(X) 
	cmb <- expand.grid(i=1:n, j=1:n) 
	simdt <- matrix(apply(cmb,1,cos.sim),n,n)
	rownames(simdt) = rownames(mtt)
	hc <- hclust(dist(simdt, method = "euclidean"), method = 'ave')
	# hc <- hclust(dist(simdt)^2, method = 'cen')
	
	plot(hc, xlab = '')
	k = 10
	groups <- cutree(hc, k=k)  # cut tree into 5 clusters
	rect.hclust(hc, k=k, border="red") # draw dendogram with red borders 
{:lang="ruby"}	

看一下效果吧：

![](http://farm8.staticflickr.com/7302/9699627576_6744f02576_c.jpg)

当然了，如果你觉得这个方法过于粗暴，还可以尝试构建主题网络并进行社区划分的方法。不再赘述。